import cv2
import torch
import pyrealsense2 as rs
import numpy as np

# YOLOv5 모델 로드
model = torch.hub.load('ultralytics/yolov5', 'custom', path='tomato.pt')

# Realsense 카메라 설정
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)

# Realsense 카메라 시작
pipeline.start(config)

# 깊이 프로파일링 프로세서 생성
profile = pipeline.get_active_profile()
depth_profile = profile.get_stream(rs.stream.depth)
depth_intrinsics = depth_profile.as_video_stream_profile().get_intrinsics()

while True:
    # 프레임 가져오기
    frames = pipeline.wait_for_frames()
    color_frame = frames.get_color_frame()
    depth_frame = frames.get_depth_frame()
    if not color_frame or not depth_frame:
        continue
    color_image = np.asanyarray(color_frame.get_data())
    depth_image = np.asanyarray(depth_frame.get_data())

    # YOLOv5를 사용하여 물체 감지
    results = model(color_image)

    # 검출된 물체의 좌표와 클래스 출력
    for detection in results.xyxy[0]:
        if detection[5] == 0:  # "tomato" 클래스 라벨을 나타내는 인덱스
            x, y, w, h = detection[:4]
            label = f"{results.names[int(detection[5])]}: {detection[4]:.2f}"
            cv2.rectangle(color_image, (int(x), int(y)), (int(w), int(h)), (0, 255, 0), 2)
            cv2.putText(color_image, label, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

            # 물체의 중심 좌표 계산
            center_x = int((x + w) / 2)
            center_y = int((y + h) / 2)

            # 물체의 3D 좌표 계산
            depth = depth_image[center_y, center_x].astype(float)
            depth_scale = pipeline.get_active_profile().get_device().first_depth_sensor().get_depth_scale()
            depth_in_meters = depth * depth_scale

            # 3D 좌표 계산
            point_in_3D = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [center_x, center_y], depth_in_meters)

            # 광학 중심 또는 이미지 픽셀 중심을 기준으로한 좌표 출력
            print(f"Object Detected: X={point_in_3D[0]:.2f}, Y={point_in_3D[1]:.2f}, Z={point_in_3D[2]:.2f}")

    # 프레임 출력
    cv2.imshow('Webcam', color_image)

    # 'q' 키를 누르면 종료
    if cv2.waitKey(1) == ord('q'):
        break

# Realsense 카메라 종료
pipeline.stop()
cv2.destroyAllWindows()
